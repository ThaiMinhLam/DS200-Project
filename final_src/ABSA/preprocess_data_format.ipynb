{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5886b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c37490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DRINK#QUALITY', 'FOOD#QUALITY', 'LOCATION', 'DRINK#VARIETY', 'ENVIRONMENT', 'SERVICE#STAFF', 'PRICE', 'SERVICE#ORDER'}\n",
      "✅ Split xong: 40800 train, 5100 val, 5101 test\n"
     ]
    }
   ],
   "source": [
    "with open(r\"F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\drinkplaces_labeled_full.json\", 'r', encoding='utf-8') as file:\n",
    "    raw = json.load(file)\n",
    "\n",
    "data = []\n",
    "unique_label = set()\n",
    "for idx, item in enumerate(raw):\n",
    "    inner = list(item.values())[0]\n",
    "    label_dict = inner['label']\n",
    "    if len(label_dict) != 0:\n",
    "        data.append({list(item.keys())[0]: inner})\n",
    "        for label in list(label_dict.keys()):\n",
    "            unique_label.add(label)\n",
    "print(unique_label)\n",
    "random.shuffle(data)\n",
    "\n",
    "n = len(data)\n",
    "train_end = int(0.8 * n)\n",
    "val_end = int(0.9 * n)\n",
    "\n",
    "train_data = data[:train_end]\n",
    "val_data = data[train_end:val_end]\n",
    "test_data = data[val_end:]\n",
    "\n",
    "with open(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\val.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(val_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Split xong: {len(train_data)} train, {len(val_data)} val, {len(test_data)} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Split xong: 52713 train, 6589 val, 6590 test\n"
     ]
    }
   ],
   "source": [
    "# with open(r\"F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\drinkplaces_labeled_full.json\", 'r', encoding='utf-8') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# random.shuffle(data)\n",
    "\n",
    "# n = len(data)\n",
    "# train_end = int(0.8 * n)\n",
    "# val_end = int(0.9 * n)\n",
    "\n",
    "# train_data = data[:train_end]\n",
    "# val_data = data[train_end:val_end]\n",
    "# test_data = data[val_end:]\n",
    "\n",
    "# with open(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\train.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# with open(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\val.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(val_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# with open(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\test.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# print(f\"✅ Split xong: {len(train_data)} train, {len(val_data)} val, {len(test_data)} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa024df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {'NEGATIVE': 'negative', 'NEUTRAL': 'neutral', 'POSITIVE': 'positive'}\n",
    "\n",
    "def json_to_txt(json_file, txt_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "        for idx, item in enumerate(data, start=1):\n",
    "            inner = list(item.values())[0]\n",
    "            text = inner['text'].replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "            label_dict = inner['label']\n",
    "\n",
    "            f.write(f'#{idx}\\n')\n",
    "            f.write(f'{text}\\n')\n",
    "\n",
    "            label_list = [f'{{{aspect}, {sentiment_map[sentiment]}}}' \n",
    "                          for aspect, sentiment in label_dict.items()]\n",
    "            label_line = ', '.join(label_list)\n",
    "            f.write(f'{label_line}\\n\\n')\n",
    "\n",
    "\n",
    "json_to_txt(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\train.json', r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\train.txt')\n",
    "json_to_txt(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\val.json', r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\val.txt')\n",
    "json_to_txt(r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\test.json', r'F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\test.txt')\n",
    "\n",
    "# with open(r\"F:\\Studies\\Third_year\\Big_data\\Final_Code\\src\\ThamKhao\\ABSA-VLSP2018\\data\\cafe_review.txt\",'w', encoding='utf-8') as f:\n",
    "#     for idx, item in enumerate(data, start=1):\n",
    "#         inner = list(item.values())[0]\n",
    "#         text = inner['text'].replace('\\n', ' ').strip()\n",
    "\n",
    "#         label_dict = inner['label']\n",
    "\n",
    "#         f.write(f'#{idx}\\n')\n",
    "\n",
    "#         f.write(f'{text}\\n')\n",
    "        \n",
    "#         label_list = [f'{{{aspect}, {sentiment_map[sentiment]}}}' for aspect, sentiment in label_dict.items()]\n",
    "#         label_line = ', '.join(label_list)\n",
    "#         f.write(f'{label_line}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd3da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prj__env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
